{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52f87c73",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b980d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "import random\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from mdptoolbox import mdp\n",
    "from scipy.optimize import linprog\n",
    "from itertools import product   \n",
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbbeb09",
   "metadata": {},
   "source": [
    "The environment has a 4x4 grid, with a total of 16 states. There are four possible actions: move left, move down, move right, or move up. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c1edf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "slippery=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af3619c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"FrozenLake-v1\", map_name = \"4x4\", is_slippery=slippery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c17a41f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of states: 16\n",
      "Number of actions: 4\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of states:\", env.observation_space.n)\n",
    "print(\"Number of actions:\", env.action_space.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5cd4d7",
   "metadata": {},
   "source": [
    "# Initialize the Q-table:\n",
    "\n",
    "Create a Q-table with dimensions equal to the number of states and actions. Initialize the table with zeros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f43b536",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_table = np.zeros((env.observation_space.n, env.action_space.n))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febec990",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91006f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_episodes = 200000\n",
    "learning_rate = 0.05\n",
    "max_steps = 100\n",
    "gamma = 0.99\n",
    "exploration_rate = 1\n",
    "max_exploration_rate = 1\n",
    "min_exploration_rate = 0.01\n",
    "exploration_decay_rate = 0.00005"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8499e05d",
   "metadata": {},
   "source": [
    "# Q-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "505d26fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200000/200000 [01:35<00:00, 2097.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q-table:\n",
      "[[0.55263532 0.50649613 0.50523681 0.50569326]\n",
      " [0.29660964 0.35175457 0.34317249 0.49903797]\n",
      " [0.42039211 0.42387221 0.41720776 0.46295333]\n",
      " [0.32221685 0.27919144 0.30427559 0.44810524]\n",
      " [0.56787591 0.42530093 0.34738455 0.35905931]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.23984841 0.16088385 0.37644947 0.21347115]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.35816089 0.35016442 0.32749142 0.62024819]\n",
      " [0.46833035 0.68019506 0.46425814 0.43072886]\n",
      " [0.63701978 0.45661055 0.45463952 0.29763121]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.57360259 0.42503044 0.83158493 0.52724735]\n",
      " [0.73849179 0.92202668 0.79307829 0.78885498]\n",
      " [0.         0.         0.         0.        ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rewards_all_episodes = []\n",
    "\n",
    "for episode in tqdm(range(total_episodes)):\n",
    "    state = env.reset()[0]\n",
    "    done = False\n",
    "    rewards_current_episode = 0\n",
    "\n",
    "    for step in range(max_steps):\n",
    "        exploration_threshold = random.uniform(0, 1)\n",
    "        if exploration_threshold > exploration_rate:\n",
    "            action = np.argmax(q_table[state, :])\n",
    "        else:\n",
    "            action = env.action_space.sample()\n",
    "        new_state, reward, done, info, prob = env.step(action)\n",
    "\n",
    "        q_table[state, action] = q_table[state, action] * (1 - learning_rate) + \\\n",
    "            learning_rate * (reward + gamma * np.max(q_table[new_state, :]))\n",
    "        state = new_state\n",
    "        rewards_current_episode += reward\n",
    "        if done:\n",
    "            break\n",
    "    exploration_rate = min_exploration_rate + \\\n",
    "        (max_exploration_rate - min_exploration_rate) * np.exp(-exploration_decay_rate * episode)\n",
    "    rewards_all_episodes.append(rewards_current_episode)\n",
    "\n",
    "print(\"Q-table:\")\n",
    "print(q_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8223b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_policy(policy):\n",
    "    reshaped_policy = policy.reshape(4,4)\n",
    "    plt.imshow([[0,0,0,0],[0,1,0,1],[0,0,0,1],[1,0,0,-1] ], cmap=mpl.colormaps[\"Pastel1\"], interpolation='nearest')\n",
    "\n",
    "    #left arrow if action is 0\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            if reshaped_policy[i][j] == 0:\n",
    "                plt.annotate('', xy=(j,i), xytext=(j+0.3,i), arrowprops=dict(facecolor='black', width=0.5, headwidth=5))\n",
    "    #down arrow if action is 1\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            if reshaped_policy[i][j] == 1:\n",
    "                plt.annotate('', xy=(j,i), xytext=(j,i-0.3), arrowprops=dict(facecolor='black', width=0.5, headwidth=5))\n",
    "    #right arrow if action is 2\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            if reshaped_policy[i][j] == 2:\n",
    "                plt.annotate('', xy=(j,i), xytext=(j-0.3,i), arrowprops=dict(facecolor='black', width=0.5, headwidth=5))\n",
    "    #up arrow if action is 3\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            if reshaped_policy[i][j] == 3:\n",
    "                plt.annotate('', xy=(j,i), xytext=(j,i+0.3), arrowprops=dict(facecolor='black', width=0.5, headwidth=5))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86afbe9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "policy = np.argmax(q_table,axis=1)\n",
    "\n",
    "plot_policy(policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1eb6f89",
   "metadata": {},
   "source": [
    "# Evaluate the agent's performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c45936f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********* Average reward per 10 thousand episodes *********\n",
      "\n",
      "10000 :  0.02739999999999989\n",
      "20000 :  0.07170000000000103\n",
      "30000 :  0.14959999999999984\n",
      "40000 :  0.2505999999999887\n",
      "50000 :  0.3741999999999751\n",
      "60000 :  0.45829999999996585\n",
      "70000 :  0.5458999999999562\n",
      "80000 :  0.5961999999999507\n",
      "90000 :  0.6272999999999472\n",
      "100000 :  0.6582999999999438\n",
      "110000 :  0.6632999999999433\n",
      "120000 :  0.6759999999999419\n",
      "130000 :  0.6762999999999418\n",
      "140000 :  0.6868999999999407\n",
      "150000 :  0.6948999999999398\n",
      "160000 :  0.6847999999999409\n",
      "170000 :  0.6810999999999413\n",
      "180000 :  0.6876999999999406\n",
      "190000 :  0.6866999999999407\n",
      "200000 :  0.6869999999999407\n"
     ]
    }
   ],
   "source": [
    "rewards_per_thousand_episodes = np.split(np.array(rewards_all_episodes), total_episodes / 10000)\n",
    "count = 10000\n",
    "print(\"********* Average reward per 10 thousand episodes *********\\n\")\n",
    "for r in rewards_per_thousand_episodes:\n",
    "    print(count, \": \", str(sum(r / 10000)))\n",
    "    count += 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17052b7c",
   "metadata": {},
   "source": [
    "# Test performance "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90ef810",
   "metadata": {},
   "source": [
    "Require pygame and opens a new window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98e95b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_test_episodes = 3\n",
    "env = gym.make(\"FrozenLake-v1\", map_name = \"4x4\", is_slippery=slippery, render_mode=\"human\")\n",
    "for episode in range(num_test_episodes):\n",
    "    state = env.reset()[0]\n",
    "    done = False\n",
    "    for step in range(max_steps):\n",
    "        action = np.argmax(q_table[state, :])\n",
    "        new_state, reward, done, info, prob = env.step(action)\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "        state = new_state\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291e0a84",
   "metadata": {},
   "source": [
    "# IRL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea1922d",
   "metadata": {},
   "source": [
    "Now, given the q-table, we try to recover the reward function "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb14aae8",
   "metadata": {},
   "source": [
    "# Maximum margin method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e618e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 1646.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward Function:\n",
      "[0.02249668 0.02249668 0.02249668 0.02249668 0.02249668 0.\n",
      " 0.02249668 0.         0.02249668 0.02249668 0.02249668 0.\n",
      " 0.         0.02249668 0.02249668 0.        ]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def compute_feature_expectations(env, policy, num_states, num_actions, discount_factor, num_trajectories, trajectory_length):\n",
    "    feature_expectations = np.zeros(num_states)\n",
    "\n",
    "    for _ in range(num_trajectories):\n",
    "        state = env.reset()[0]\n",
    "        for _ in range(trajectory_length):\n",
    "            action = policy[state]\n",
    "            feature_expectations[state] += discount_factor \n",
    "            state, _, done, _, _ = env.step(action)\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "    return feature_expectations / num_trajectories\n",
    "\n",
    "def max_margin_irl(feature_matrix, feature_expectations, num_states, num_actions, discount_factor, num_trajectories, trajectory_length):\n",
    "    c = np.concatenate([np.zeros(num_states), np.ones(num_trajectories)])\n",
    "    A_ub = []\n",
    "    b_ub = []\n",
    "\n",
    "    for trajectory in tqdm(range(num_trajectories)):\n",
    "        state = env.reset()[0]\n",
    "        for t in range(trajectory_length):\n",
    "            action = np.argmax(q_table[state, :])\n",
    "            next_state, _, done, _, _ = env.step(action)\n",
    "            immediate_reward = feature_matrix[state, :] - discount_factor * feature_matrix[next_state, :] \n",
    "            A_ub.append(np.concatenate([-immediate_reward, np.zeros(num_trajectories)]))\n",
    "            A_ub[-1][num_states + trajectory] = -1.0\n",
    "            b_ub.append(0)\n",
    "            state = next_state\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "    A_eq = [np.concatenate([feature_expectations, np.zeros(num_trajectories)])]\n",
    "    b_eq = [1]\n",
    "\n",
    "    bounds = [(0, None) for _ in range(num_states)] + [(None, None) for _ in range(num_trajectories)]\n",
    "\n",
    "    result = linprog(c, A_ub=A_ub, b_ub=b_ub, A_eq=A_eq, b_eq=b_eq, bounds=bounds)\n",
    "\n",
    "    return result.x[:num_states]\n",
    "\n",
    "# Hyperparameters\n",
    "num_states = env.observation_space.n\n",
    "num_actions = env.action_space.n\n",
    "discount_factor = 1\n",
    "num_trajectories = 1000\n",
    "trajectory_length = 100\n",
    "\n",
    "env = gym.make(\"FrozenLake-v1\", map_name = \"4x4\", is_slippery=slippery)\n",
    "feature_matrix = np.eye(num_states)\n",
    "expert_policy = np.argmax(q_table, axis=1)\n",
    "feature_expectations = compute_feature_expectations(env, expert_policy, num_states, num_actions, discount_factor, num_trajectories, trajectory_length)\n",
    "\n",
    "reward_function = max_margin_irl(feature_matrix, feature_expectations, num_states, num_actions, discount_factor, num_trajectories, trajectory_length)\n",
    "\n",
    "print(\"Reward Function:\")\n",
    "print(reward_function)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "545cf907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1558bb790>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(reward_function.reshape(4,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efadc23",
   "metadata": {},
   "source": [
    "strange result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb79f57",
   "metadata": {},
   "source": [
    "# Max entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d92d7f",
   "metadata": {},
   "source": [
    "Implementation is a modification of this repo https://github.com/qzed/irl-maxent/tree/master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27f3ec14",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer:\n",
    "    \"\"\"\n",
    "    Optimizer base-class.\n",
    "\n",
    "    Note:\n",
    "        Before use of any optimizer, its `reset` function must be called.\n",
    "\n",
    "    Attributes:\n",
    "        parameters: The parameters to be optimized. This should only be set\n",
    "            via the `reset` method of this optimizer.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.parameters = None\n",
    "\n",
    "    def reset(self, parameters):\n",
    "        \"\"\"\n",
    "        Reset this optimizer.\n",
    "\n",
    "        Args:\n",
    "            parameters: The parameters to optimize.\n",
    "        \"\"\"\n",
    "        self.parameters = parameters\n",
    "\n",
    "    def step(self, grad, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Perform a single optimization step.\n",
    "\n",
    "        Args:\n",
    "            grad: The gradient used for the optimization step.\n",
    "\n",
    "            Other arguments are optimizer-specific.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def normalize_grad(self, ord=None):\n",
    "        \"\"\"\n",
    "        Create a new wrapper for this optimizer which normalizes the\n",
    "        gradient before each step.\n",
    "\n",
    "        Returns:\n",
    "            An Optimizer instance wrapping this Optimizer, normalizing the\n",
    "            gradient before each step.\n",
    "\n",
    "        See also:\n",
    "            `class NormalizeGrad`\n",
    "        \"\"\"\n",
    "        return NormalizeGrad(self, ord)\n",
    "\n",
    "class ExpSga(Optimizer):\n",
    "    \"\"\"\n",
    "    Exponentiated stochastic gradient ascent.\n",
    "\n",
    "    The implementation follows Algorithm 10.5 from B. Ziebart's thesis\n",
    "    (2010) and is slightly adapted from the original algorithm provided by\n",
    "    Kivinen and Warmuth (1997).\n",
    "\n",
    "    Note:\n",
    "        Before use of any optimizer, its `reset` function must be called.\n",
    "\n",
    "    Args:\n",
    "        lr: The learning-rate. This may either be a float for a constant\n",
    "            learning-rate or a function\n",
    "            `(k: Integer) -> learning_rate: Float`\n",
    "            taking the step number as parameter and returning a learning\n",
    "            rate as result.\n",
    "            See also `linear_decay`, `power_decay` and `exponential_decay`.\n",
    "        normalize: A boolean specifying if the the parameters should be\n",
    "            normalized after each step, as done in the original algorithm by\n",
    "            Kivinen and Warmuth (1997).\n",
    "\n",
    "    Attributes:\n",
    "        parameters: The parameters to be optimized. This should only be set\n",
    "            via the `reset` method of this optimizer.\n",
    "        lr: The learning-rate as specified in the __init__ function.\n",
    "        k: The number of steps run since the last reset.\n",
    "    \"\"\"\n",
    "    def __init__(self, lr, normalize=False):\n",
    "        super().__init__()\n",
    "        self.lr = lr\n",
    "        self.normalize = normalize\n",
    "        self.k = 0\n",
    "\n",
    "    def reset(self, parameters):\n",
    "        \"\"\"\n",
    "        Reset this optimizer.\n",
    "\n",
    "        Args:\n",
    "            parameters: The parameters to optimize.\n",
    "        \"\"\"\n",
    "        super().reset(parameters)\n",
    "        self.k = 0\n",
    "\n",
    "    def step(self, grad, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Perform a single optimization step.\n",
    "\n",
    "        Args:\n",
    "            grad: The gradient used for the optimization step.\n",
    "        \"\"\"\n",
    "        lr = self.lr if not callable(self.lr) else self.lr(self.k)\n",
    "        self.k += 1\n",
    "\n",
    "        self.parameters *= np.exp(lr * grad)\n",
    "\n",
    "        if self.normalize:\n",
    "            self.parameters /= self.parameters.sum()\n",
    "\n",
    "class Initializer:\n",
    "    \"\"\"\n",
    "    Base-class for an Initializer, specifying a strategy for parameter\n",
    "    initialization.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def initialize(self, shape):\n",
    "        \"\"\"\n",
    "        Create an initial set of parameters.\n",
    "\n",
    "        Args:\n",
    "            shape: The shape of the parameters.\n",
    "\n",
    "        Returns:\n",
    "            An initial set of parameters of the given shape, adhering to the\n",
    "            initialization-strategy described by this Initializer.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def __call__(self, shape):\n",
    "        \"\"\"\n",
    "        Create an initial set of parameters.\n",
    "\n",
    "        Note:\n",
    "            This function simply calls `self.initialize(shape)`.\n",
    "\n",
    "        Args:\n",
    "            shape: The shape of the parameters.\n",
    "\n",
    "        Returns:\n",
    "            An initial set of parameters of the given shape, adhering to the\n",
    "            initialization-strategy described by this Initializer.\n",
    "        \"\"\"\n",
    "        return self.initialize(shape)\n",
    "class Constant(Initializer):\n",
    "    \"\"\"\n",
    "    An Initializer, initializing parameters to a constant value.\n",
    "\n",
    "    Args:\n",
    "        value: Either a scalar value or a function in dependence on the\n",
    "            shape of the parameters, returning a scalar value for\n",
    "            initialization.\n",
    "    \"\"\"\n",
    "    def __init__(self, value=1.0):\n",
    "        super().__init__()\n",
    "        self.value = value\n",
    "\n",
    "    def initialize(self, shape):\n",
    "        \"\"\"\n",
    "        Create set of parameters with initial fixed value.\n",
    "\n",
    "        The scalar value used for initialization can be specified in the\n",
    "        constructor.\n",
    "\n",
    "        Args:\n",
    "            shape: The shape of the parameters.\n",
    "\n",
    "        Returns:\n",
    "            An set of constant-valued parameters of the given shape.\n",
    "        \"\"\"\n",
    "        if callable(self.value):\n",
    "            return np.ones(shape) * self.value(shape)\n",
    "        else:\n",
    "            return np.ones(shape) * self.value\n",
    "\n",
    "def linear_decay(lr0=0.2, decay_rate=1.0, decay_steps=1):\n",
    "    \"\"\"\n",
    "    Linear learning-rate decay.\n",
    "\n",
    "    Creates a function `(k: Integer) -> learning_rate: Float` returning the\n",
    "    learning-rate in dependence on the current number of iterations. The\n",
    "    returned function can be expressed as\n",
    "\n",
    "        learning_rate(k) = lr0 / (1.0 + decay_rate * floor(k / decay_steps))\n",
    "\n",
    "    Args:\n",
    "        lr0: The initial learning-rate.\n",
    "        decay_rate: The decay factor.\n",
    "        decay_steps: An integer number of steps that can be used to\n",
    "            staircase the learning-rate.\n",
    "\n",
    "    Returns:\n",
    "        The function giving the current learning-rate in dependence of the\n",
    "        current iteration as specified above.\n",
    "    \"\"\"\n",
    "    def _lr(k):\n",
    "        return lr0 / (1.0 + decay_rate * np.floor(k / decay_steps))\n",
    "\n",
    "    return _lr\n",
    "\n",
    "def create_expert_trajectory(env, policy, n_trajectories):\n",
    "    env.reset()\n",
    "    trajectories = []\n",
    "    expert_trajectory = []\n",
    "    done = False\n",
    "    for i in range(n_trajectories):\n",
    "        while not done:\n",
    "            action = policy[env.s]\n",
    "            state, reward, done, info, prob = env.step(action)\n",
    "            expert_trajectory.append([state, action])\n",
    "        env.reset()\n",
    "        trajectories.append(expert_trajectory)\n",
    "        expert_trajectory = []\n",
    "        done = False\n",
    "    return trajectories\n",
    "\n",
    "\n",
    "\n",
    "def feature_expectation_from_trajectories(features, trajectories):\n",
    "    n_states, n_features = features.shape\n",
    "\n",
    "    fe = np.zeros(n_features)\n",
    "\n",
    "    for t in trajectories:\n",
    "        states = [k[0] for k in t]# for each trajectory\n",
    "        for s in states:                # for each state in trajectory\n",
    "            fe += features[s, :]            # sum-up features\n",
    "\n",
    "    return fe / len(trajectories)           # average over trajectories\n",
    "\n",
    "def transition_matrix(env):\n",
    "    transition_matrix = np.zeros((env.observation_space.n, env.observation_space.n, env.action_space.n))\n",
    "    for i in range(env.observation_space.n):\n",
    "        for j in range(env.action_space.n):\n",
    "            for prob, next_state, reward, done in env.P[i][j]:\n",
    "                transition_matrix[i][next_state][j] += prob\n",
    "    return transition_matrix\n",
    "\n",
    "def compute_expected_svf(p_transition, p_initial, terminal, reward, eps=1e-6):\n",
    "    n_states, _, n_actions = p_transition.shape\n",
    "    \n",
    "    nonterminal = set(range(n_states)) - set(terminal)  # nonterminal states\n",
    "    \n",
    "    # Backward Pass\n",
    "    # 1. initialize at terminal states\n",
    "    zs = np.zeros(n_states, dtype=np.float32)                            # zs: state partition function\n",
    "    zs[terminal] = 1.0\n",
    "\n",
    "    # 2. perform backward pass\n",
    "    for _ in range(2 * n_states):                       # longest trajectory: n_states\n",
    "        # reset action values to zero\n",
    "        za = np.zeros((n_states, n_actions), dtype=np.float32)            # za: action partition function\n",
    "\n",
    "        # for each state-action pair\n",
    "        for s_from, a in product(range(n_states), range(n_actions)):\n",
    "\n",
    "            # sum over s_to\n",
    "            for s_to in range(n_states):\n",
    "                za[s_from, a] += p_transition[s_from, s_to, a] * np.exp(reward[s_from]) * zs[s_to]\n",
    "                \n",
    "        # sum over all actions\n",
    "        \n",
    "        zs = za.sum(axis=1)\n",
    "        \n",
    "        \n",
    "\n",
    "    # 3. compute local action probabilities\n",
    "    \n",
    "    p_action = za / zs[:, None]\n",
    "    \n",
    "    # Forward Pass\n",
    "    # 4. initialize with starting probability\n",
    "    d = np.zeros((n_states, 2 * n_states))              # d: state-visitation frequencies\n",
    "    d[:, 0] = p_initial\n",
    "\n",
    "    # 5. iterate for N steps\n",
    "    for t in range(1, 2 * n_states):                    # longest trajectory: n_states\n",
    "        \n",
    "        # for all states\n",
    "        for s_to in range(n_states):\n",
    "            \n",
    "            # sum over nonterminal state-action pairs\n",
    "            for s_from, a in product(nonterminal, range(n_actions)):\n",
    "                d[s_to, t] += d[s_from, t-1] * p_action[s_from, a] * p_transition[s_from, s_to, a]\n",
    "\n",
    "    # 6. sum-up frequencies\n",
    "    return d.sum(axis=1)\n",
    "\n",
    "def maxent_irl(p_transition, features, terminal, trajectories, optim, init, eps=1e-4):\n",
    "    n_states, _, n_actions = p_transition.shape\n",
    "    _, n_features = features.shape\n",
    "\n",
    "    # compute feature expectation from trajectories\n",
    "    e_features = feature_expectation_from_trajectories(features, trajectories)\n",
    "    \n",
    "    # compute starting-state probabilities from trajectories\n",
    "    p_initial = np.zeros(n_states)\n",
    "    p_initial[0] = 1\n",
    "    \n",
    "\n",
    "    # gradient descent optimization\n",
    "    omega = init(n_features)        # initialize our parameters\n",
    "    delta = np.inf                  # initialize delta for convergence check\n",
    "\n",
    "    optim.reset(omega)              # re-start optimizer\n",
    "    while delta > eps:              # iterate until convergence\n",
    "        \n",
    "        omega_old = omega.copy()\n",
    "\n",
    "        # compute per-state reward from features\n",
    "        reward = features.dot(omega)\n",
    "        \n",
    "        reward = reward/reward.max()\n",
    "        \n",
    "        # compute gradient of the log-likelihood\n",
    "        e_svf = compute_expected_svf(p_transition, p_initial, terminal, reward)\n",
    "        grad = e_features - features.T.dot(e_svf)\n",
    "\n",
    "        # perform optimization step and compute delta for convergence\n",
    "        optim.step(grad)\n",
    "        \n",
    "        # re-compute detla for convergence check\n",
    "        delta = np.max(np.abs(omega_old - omega))\n",
    "\n",
    "    # re-compute per-state reward and return\n",
    "    return features.dot(omega)\n",
    "\n",
    "policy = np.argmax(q_table, axis=1)\n",
    "n_trajectories = 1000\n",
    "trajectories = create_expert_trajectory(env, policy, n_trajectories)\n",
    "\n",
    "# set up features: we use one feature vector per state\n",
    "features = np.identity(env.observation_space.n)\n",
    "\n",
    "# choose our parameter initialization strategy:\n",
    "#   initialize parameters with constant\n",
    "init = Constant(1.0)\n",
    "\n",
    "# choose our optimization strategy:\n",
    "#   we select exponentiated stochastic gradient descent with linear learning-rate decay\n",
    "optim = ExpSga(lr=linear_decay(lr0=0.01))\n",
    "transition_matrix_env = transition_matrix(env)\n",
    "\n",
    "\n",
    "# actually do some inverse reinforcement learning\n",
    "reward_maxent = maxent_irl(transition_matrix_env, features, [5,7,11,12,15], trajectories, optim, init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85a7c7cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1559cfad0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(reward_maxent.reshape(4,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fe8a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_episodes = 200000\n",
    "learning_rate = 0.01\n",
    "max_steps = 100\n",
    "gamma = 0.99\n",
    "exploration_rate = 1\n",
    "max_exploration_rate = 1\n",
    "min_exploration_rate = 0.01\n",
    "exploration_decay_rate = 0.00005\n",
    "# Define Q-learning parameters\n",
    "\n",
    "max_steps = 100\n",
    "alpha = 0.8\n",
    "\n",
    "epsilon = 1.0\n",
    "max_epsilon = 1.0\n",
    "min_epsilon = 0.01\n",
    "decay_rate = 0.01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa0cacc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [01:08<00:00, 1458.34it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create environment\n",
    "env = gym.make('FrozenLake-v1', map_name=\"4x4\", is_slippery=slippery)\n",
    "\n",
    "# Initialize Q-table to zeros\n",
    "new_q_table = np.zeros((env.observation_space.n, env.action_space.n))\n",
    "rewards_all_episodes = []\n",
    "\n",
    "for episode in tqdm(range(total_episodes)):\n",
    "    state = env.reset()[0]\n",
    "    done = False\n",
    "    rewards_current_episode = 0\n",
    "\n",
    "    for step in range(max_steps):\n",
    "        exploration_threshold = random.uniform(0, 1)\n",
    "        if exploration_threshold > exploration_rate:\n",
    "            action = np.argmax(new_q_table[state, :])\n",
    "        else:\n",
    "            action = env.action_space.sample()\n",
    "        new_state, _, done, info, prob = env.step(action)\n",
    "        reward = reward_maxent[new_state]\n",
    "        new_q_table[state, action] = new_q_table[state, action] * (1 - learning_rate) + \\\n",
    "            learning_rate * (reward + gamma * np.max(new_q_table[new_state, :]))\n",
    "        state = new_state\n",
    "        rewards_current_episode += reward\n",
    "        if done:\n",
    "            break\n",
    "    exploration_rate = min_exploration_rate + \\\n",
    "        (max_exploration_rate - min_exploration_rate) * np.exp(-exploration_decay_rate * episode)\n",
    "    rewards_all_episodes.append(rewards_current_episode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e48680a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 3 3 3 0 0 2 0 3 1 0 0 0 2 1 0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "expert_policy = np.argmax(q_table,axis=1)\n",
    "print(expert_policy)\n",
    "plot_policy(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "28dcbe5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 3 3 3 0 0 2 0 3 1 0 0 0 2 0 0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learned_policy = np.argmax(new_q_table,axis=1)\n",
    "print(learned_policy)\n",
    "plot_policy(learned_policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3562258b",
   "metadata": {},
   "source": [
    "Observation: the agent will never reach the goal! that's because he is maximixing the reward of staying in the first cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8c5ff8",
   "metadata": {},
   "source": [
    "# Negative Max entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc405cf3",
   "metadata": {},
   "source": [
    "Here we add the negative examples: the agent should not do long walks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "990c0e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer:\n",
    "    \"\"\"\n",
    "    Optimizer base-class.\n",
    "\n",
    "    Note:\n",
    "        Before use of any optimizer, its `reset` function must be called.\n",
    "\n",
    "    Attributes:\n",
    "        parameters: The parameters to be optimized. This should only be set\n",
    "            via the `reset` method of this optimizer.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.parameters = None\n",
    "\n",
    "    def reset(self, parameters):\n",
    "        \"\"\"\n",
    "        Reset this optimizer.\n",
    "\n",
    "        Args:\n",
    "            parameters: The parameters to optimize.\n",
    "        \"\"\"\n",
    "        self.parameters = parameters\n",
    "\n",
    "    def step(self, grad, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Perform a single optimization step.\n",
    "\n",
    "        Args:\n",
    "            grad: The gradient used for the optimization step.\n",
    "\n",
    "            Other arguments are optimizer-specific.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def normalize_grad(self, ord=None):\n",
    "        \"\"\"\n",
    "        Create a new wrapper for this optimizer which normalizes the\n",
    "        gradient before each step.\n",
    "\n",
    "        Returns:\n",
    "            An Optimizer instance wrapping this Optimizer, normalizing the\n",
    "            gradient before each step.\n",
    "\n",
    "        See also:\n",
    "            `class NormalizeGrad`\n",
    "        \"\"\"\n",
    "        return NormalizeGrad(self, ord)\n",
    "\n",
    "class ExpSga(Optimizer):\n",
    "    \"\"\"\n",
    "    Exponentiated stochastic gradient ascent.\n",
    "\n",
    "    The implementation follows Algorithm 10.5 from B. Ziebart's thesis\n",
    "    (2010) and is slightly adapted from the original algorithm provided by\n",
    "    Kivinen and Warmuth (1997).\n",
    "\n",
    "    Note:\n",
    "        Before use of any optimizer, its `reset` function must be called.\n",
    "\n",
    "    Args:\n",
    "        lr: The learning-rate. This may either be a float for a constant\n",
    "            learning-rate or a function\n",
    "            `(k: Integer) -> learning_rate: Float`\n",
    "            taking the step number as parameter and returning a learning\n",
    "            rate as result.\n",
    "            See also `linear_decay`, `power_decay` and `exponential_decay`.\n",
    "        normalize: A boolean specifying if the the parameters should be\n",
    "            normalized after each step, as done in the original algorithm by\n",
    "            Kivinen and Warmuth (1997).\n",
    "\n",
    "    Attributes:\n",
    "        parameters: The parameters to be optimized. This should only be set\n",
    "            via the `reset` method of this optimizer.\n",
    "        lr: The learning-rate as specified in the __init__ function.\n",
    "        k: The number of steps run since the last reset.\n",
    "    \"\"\"\n",
    "    def __init__(self, lr, normalize=False):\n",
    "        super().__init__()\n",
    "        self.lr = lr\n",
    "        self.normalize = normalize\n",
    "        self.k = 0\n",
    "\n",
    "    def reset(self, parameters):\n",
    "        \"\"\"\n",
    "        Reset this optimizer.\n",
    "\n",
    "        Args:\n",
    "            parameters: The parameters to optimize.\n",
    "        \"\"\"\n",
    "        super().reset(parameters)\n",
    "        self.k = 0\n",
    "\n",
    "    def step(self, grad, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Perform a single optimization step.\n",
    "\n",
    "        Args:\n",
    "            grad: The gradient used for the optimization step.\n",
    "        \"\"\"\n",
    "        lr = self.lr if not callable(self.lr) else self.lr(self.k)\n",
    "        self.k += 1\n",
    "\n",
    "        self.parameters *= np.exp(lr * grad)\n",
    "\n",
    "        if self.normalize:\n",
    "            self.parameters /= self.parameters.sum()\n",
    "\n",
    "class Initializer:\n",
    "    \"\"\"\n",
    "    Base-class for an Initializer, specifying a strategy for parameter\n",
    "    initialization.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def initialize(self, shape):\n",
    "        \"\"\"\n",
    "        Create an initial set of parameters.\n",
    "\n",
    "        Args:\n",
    "            shape: The shape of the parameters.\n",
    "\n",
    "        Returns:\n",
    "            An initial set of parameters of the given shape, adhering to the\n",
    "            initialization-strategy described by this Initializer.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def __call__(self, shape):\n",
    "        \"\"\"\n",
    "        Create an initial set of parameters.\n",
    "\n",
    "        Note:\n",
    "            This function simply calls `self.initialize(shape)`.\n",
    "\n",
    "        Args:\n",
    "            shape: The shape of the parameters.\n",
    "\n",
    "        Returns:\n",
    "            An initial set of parameters of the given shape, adhering to the\n",
    "            initialization-strategy described by this Initializer.\n",
    "        \"\"\"\n",
    "        return self.initialize(shape)\n",
    "class Constant(Initializer):\n",
    "    \"\"\"\n",
    "    An Initializer, initializing parameters to a constant value.\n",
    "\n",
    "    Args:\n",
    "        value: Either a scalar value or a function in dependence on the\n",
    "            shape of the parameters, returning a scalar value for\n",
    "            initialization.\n",
    "    \"\"\"\n",
    "    def __init__(self, value=1.0):\n",
    "        super().__init__()\n",
    "        self.value = value\n",
    "\n",
    "    def initialize(self, shape):\n",
    "        \"\"\"\n",
    "        Create set of parameters with initial fixed value.\n",
    "\n",
    "        The scalar value used for initialization can be specified in the\n",
    "        constructor.\n",
    "\n",
    "        Args:\n",
    "            shape: The shape of the parameters.\n",
    "\n",
    "        Returns:\n",
    "            An set of constant-valued parameters of the given shape.\n",
    "        \"\"\"\n",
    "        if callable(self.value):\n",
    "            return np.ones(shape) * self.value(shape)\n",
    "        else:\n",
    "            return np.ones(shape) * self.value\n",
    "\n",
    "def linear_decay(lr0=0.2, decay_rate=1.0, decay_steps=1):\n",
    "    \"\"\"\n",
    "    Linear learning-rate decay.\n",
    "\n",
    "    Creates a function `(k: Integer) -> learning_rate: Float` returning the\n",
    "    learning-rate in dependence on the current number of iterations. The\n",
    "    returned function can be expressed as\n",
    "\n",
    "        learning_rate(k) = lr0 / (1.0 + decay_rate * floor(k / decay_steps))\n",
    "\n",
    "    Args:\n",
    "        lr0: The initial learning-rate.\n",
    "        decay_rate: The decay factor.\n",
    "        decay_steps: An integer number of steps that can be used to\n",
    "            staircase the learning-rate.\n",
    "\n",
    "    Returns:\n",
    "        The function giving the current learning-rate in dependence of the\n",
    "        current iteration as specified above.\n",
    "    \"\"\"\n",
    "    def _lr(k):\n",
    "        return lr0 / (1.0 + decay_rate * np.floor(k / decay_steps))\n",
    "\n",
    "    return _lr\n",
    "\n",
    "def create_expert_trajectory(env, policy, n_trajectories):\n",
    "    env.reset()\n",
    "    trajectories = []\n",
    "    expert_trajectory = []\n",
    "    done = False\n",
    "    for i in range(n_trajectories):\n",
    "        while not done:\n",
    "            action = policy[env.s]\n",
    "            state, reward, done, info, prob = env.step(action)\n",
    "            expert_trajectory.append([state, action])\n",
    "        env.reset()\n",
    "        if state == 15:\n",
    "            trajectories.append(expert_trajectory)\n",
    "        expert_trajectory = []\n",
    "        done = False\n",
    "    return trajectories\n",
    "\n",
    "def create_negative_trajectory(env, policy, n_trajectories):\n",
    "    env.reset()\n",
    "    trajectories = []\n",
    "    expert_trajectory = []\n",
    "    done = False\n",
    "    step = 0\n",
    "    for i in range(n_trajectories):\n",
    "        while not done:\n",
    "            step += 1\n",
    "            action = policy[env.s]\n",
    "            state, reward, done, info, prob = env.step(action)\n",
    "            expert_trajectory.append([state, action])\n",
    "            if step > 100:\n",
    "                done = True\n",
    "        step = 0\n",
    "        env.reset()\n",
    "        if state != 15:\n",
    "            trajectories.append(expert_trajectory)\n",
    "        expert_trajectory = []\n",
    "        done = False\n",
    "    return trajectories\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def feature_expectation_from_trajectories(features, trajectories):\n",
    "    n_states, n_features = features.shape\n",
    "\n",
    "    fe = np.zeros(n_features)\n",
    "\n",
    "    for t in trajectories:\n",
    "        states = [k[0] for k in t]# for each trajectory\n",
    "        for s in states:                # for each state in trajectory\n",
    "            fe += features[s, :]            # sum-up features\n",
    "\n",
    "    return fe / len(trajectories)           # average over trajectories\n",
    "\n",
    "def transition_matrix(env):\n",
    "    transition_matrix = np.zeros((env.observation_space.n, env.observation_space.n, env.action_space.n))\n",
    "    for i in range(env.observation_space.n):\n",
    "        for j in range(env.action_space.n):\n",
    "            for prob, next_state, reward, done in env.P[i][j]:\n",
    "                transition_matrix[i][next_state][j] += prob\n",
    "    return transition_matrix\n",
    "\n",
    "def compute_expected_svf(p_transition, p_initial, terminal, reward, eps=1e-6):\n",
    "    n_states, _, n_actions = p_transition.shape\n",
    "    \n",
    "    nonterminal = set(range(n_states)) - set(terminal)  # nonterminal states\n",
    "    \n",
    "    # Backward Pass\n",
    "    # 1. initialize at terminal states\n",
    "    zs = np.zeros(n_states, dtype=np.float32)                            # zs: state partition function\n",
    "    zs[terminal] = 1.0\n",
    "\n",
    "    # 2. perform backward pass\n",
    "    for _ in range(2 * n_states):                       # longest trajectory: n_states\n",
    "        # reset action values to zero\n",
    "        za = np.zeros((n_states, n_actions), dtype=np.float32)            # za: action partition function\n",
    "\n",
    "        # for each state-action pair\n",
    "        for s_from, a in product(range(n_states), range(n_actions)):\n",
    "\n",
    "            # sum over s_to\n",
    "            for s_to in range(n_states):\n",
    "                za[s_from, a] += p_transition[s_from, s_to, a] * np.exp(reward[s_from]) * zs[s_to]\n",
    "                \n",
    "        # sum over all actions\n",
    "        \n",
    "        zs = za.sum(axis=1)\n",
    "        \n",
    "        \n",
    "\n",
    "    # 3. compute local action probabilities\n",
    "    \n",
    "    p_action = za / zs[:, None]\n",
    "    \n",
    "    # Forward Pass\n",
    "    # 4. initialize with starting probability\n",
    "    d = np.zeros((n_states, 2 * n_states))              # d: state-visitation frequencies\n",
    "    d[:, 0] = p_initial\n",
    "\n",
    "    # 5. iterate for N steps\n",
    "    for t in range(1, 2 * n_states):                    # longest trajectory: n_states\n",
    "        \n",
    "        # for all states\n",
    "        for s_to in range(n_states):\n",
    "            \n",
    "            # sum over nonterminal state-action pairs\n",
    "            for s_from, a in product(nonterminal, range(n_actions)):\n",
    "                d[s_to, t] += d[s_from, t-1] * p_action[s_from, a] * p_transition[s_from, s_to, a]\n",
    "\n",
    "    # 6. sum-up frequencies\n",
    "    return d.sum(axis=1)\n",
    "\n",
    "def maxent_irl(p_transition, features, terminal, trajectories, negative_trajectories, optim, init, eps=1e-4):\n",
    "    n_states, _, n_actions = p_transition.shape\n",
    "    _, n_features = features.shape\n",
    "\n",
    "    # compute feature expectation from trajectories\n",
    "    e_features = feature_expectation_from_trajectories(features, trajectories)\n",
    "    \n",
    "    # compute feature expectation from negative trajectories\n",
    "    e_features_negative = feature_expectation_from_trajectories(features, negative_trajectories)\n",
    "\n",
    "    # compute starting-state probabilities from trajectories\n",
    "    p_initial = np.zeros(n_states)\n",
    "    p_initial[0] = 1\n",
    "    \n",
    "    # gradient descent optimization\n",
    "    omega = init(n_features)        # initialize our parameters\n",
    "    delta = np.inf                  # initialize delta for convergence check\n",
    "\n",
    "    optim.reset(omega)              # re-start optimizer\n",
    "    while delta > eps:              # iterate until convergence\n",
    "        omega_old = omega.copy()\n",
    "\n",
    "        # compute per-state reward from features\n",
    "        reward = features.dot(omega)\n",
    "        \n",
    "        reward = reward/reward.max()\n",
    "        \n",
    "        # compute gradient of the log-likelihood\n",
    "        e_svf = compute_expected_svf(p_transition, p_initial, terminal, reward)\n",
    "        e_svf_negative = compute_expected_svf(p_transition, p_initial, terminal, -reward)\n",
    "        \n",
    "        # calculate the difference between the feature expectations of positive and negative examples\n",
    "        grad = e_features - features.T.dot(e_svf)+ lambda_par*( -e_features_negative +features.T.dot(e_svf_negative))\n",
    "\n",
    "        # perform optimization step and compute delta for convergence\n",
    "        optim.step(grad)\n",
    "        \n",
    "        # re-compute detla for convergence check\n",
    "        delta = np.max(np.abs(omega_old - omega))\n",
    "\n",
    "    # re-compute per-state reward and return\n",
    "    return features.dot(omega)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "28f651da",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = np.argmax(q_table, axis=1)\n",
    "n_trajectories = 1000\n",
    "trajectories = create_expert_trajectory(env, policy, n_trajectories)\n",
    "negative_trajectories = create_negative_trajectory(env, policy, n_trajectories)\n",
    "lambda_par = 0.5 #weight for the negative examples\n",
    "\n",
    "features = np.identity(env.observation_space.n)\n",
    "\n",
    "init = Constant(1.0)\n",
    "optim = ExpSga(lr=linear_decay(lr0=0.01))\n",
    "transition_matrix_env = transition_matrix(env)\n",
    "\n",
    "reward_maxent_negative = maxent_irl(transition_matrix_env, features, [5,7,11,12,15], trajectories,negative_trajectories, optim, init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c223f55b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.71307914, 0.68942139, 0.88151892, 0.9010536 , 5.19077015,\n",
       "       0.80361872, 0.80945834, 0.79866861, 4.32328585, 2.90587192,\n",
       "       1.31960948, 0.99170171, 0.95419215, 4.3937155 , 4.40124649,\n",
       "       1.86971842])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward_maxent_negative**10 #we polarize the reward "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "155d06c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x155ba7f50>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow((reward_maxent_negative**10\n",
    "           ).reshape(4,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "130529d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_episodes = 100000\n",
    "learning_rate = 0.01\n",
    "max_steps = 100\n",
    "gamma = 0.99\n",
    "exploration_rate = 1\n",
    "max_exploration_rate = 1\n",
    "min_exploration_rate = 0.01\n",
    "exploration_decay_rate = 0.00005\n",
    "\n",
    "alpha = 0.8\n",
    "\n",
    "epsilon = 1.0\n",
    "max_epsilon = 1.0\n",
    "min_epsilon = 0.01\n",
    "decay_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5cd9649a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [01:00<00:00, 1659.38it/s]\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('FrozenLake-v1', map_name=\"4x4\", is_slippery=slippery)\n",
    "\n",
    "new_q_table_neg = np.zeros((env.observation_space.n, env.action_space.n))\n",
    "rewards_all_episodes = []\n",
    "\n",
    "for episode in tqdm(range(total_episodes)):\n",
    "    state = env.reset()[0]\n",
    "    done = False\n",
    "    rewards_current_episode = 0\n",
    "\n",
    "    for step in range(max_steps):\n",
    "        exploration_threshold = random.uniform(0, 1)\n",
    "        if exploration_threshold > exploration_rate:\n",
    "            action = np.argmax(new_q_table_neg[state, :])\n",
    "        else:\n",
    "            action = env.action_space.sample()\n",
    "        new_state, _, done, info, prob = env.step(action)\n",
    "        reward = (reward_maxent_negative**10)[new_state]\n",
    "        new_q_table_neg[state, action] = new_q_table_neg[state, action] * (1 - learning_rate) + \\\n",
    "            learning_rate * (reward + gamma * np.max(new_q_table_neg[new_state, :]))\n",
    "        state = new_state\n",
    "        rewards_current_episode += reward\n",
    "        if done:\n",
    "            break\n",
    "    exploration_rate = min_exploration_rate + \\\n",
    "        (max_exploration_rate - min_exploration_rate) * np.exp(-exploration_decay_rate * episode)\n",
    "    rewards_all_episodes.append(rewards_current_episode)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b769c15d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 3 3 3 0 0 2 0 3 1 0 0 0 2 1 0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "expert_policy = np.argmax(q_table,axis=1)\n",
    "print(expert_policy)\n",
    "plot_policy(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "117e5c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 3 3 3 0 0 0 0 3 1 0 0 0 2 0 0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learned_policy_neg = np.argmax(new_q_table_neg,axis=1)\n",
    "print(learned_policy_neg)\n",
    "plot_policy(learned_policy_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e1486fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expert success rate:  0.857\n",
      "New agent success rate:  0.879\n"
     ]
    }
   ],
   "source": [
    "class QLearningAgent:\n",
    "    def __init__(self, q_table):\n",
    "        self.q_table = q_table\n",
    "\n",
    "    def choose_action(self, state):\n",
    "        return np.argmax(self.q_table[state, :])\n",
    "\n",
    "expert_agent = QLearningAgent(q_table)\n",
    "new_agent = QLearningAgent(new_q_table_neg)\n",
    "\n",
    "def evaluate_agent(env, agent, episodes=1000):\n",
    "    success = 0\n",
    "    for _ in range(episodes):\n",
    "        state = env.reset()[0]\n",
    "        done = False\n",
    "        while not done:\n",
    "            action = agent.choose_action(state)\n",
    "            next_state, _, done, _, _ = env.step(action)\n",
    "            state = next_state\n",
    "            if env.unwrapped.s == 14:  \n",
    "                success += 1\n",
    "                done = True\n",
    "    return success / episodes\n",
    "env = gym.make('FrozenLake-v1', map_name=\"4x4\", is_slippery=slippery)\n",
    "\n",
    "expert_success_rate = evaluate_agent(env, expert_agent)\n",
    "new_agent_success_rate = evaluate_agent(env, new_agent)\n",
    "\n",
    "print(\"Expert success rate: \", expert_success_rate)\n",
    "print(\"New agent success rate: \", new_agent_success_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823c3196",
   "metadata": {},
   "source": [
    "We agent is still not reaching the goal, but it's reaching the tile before the goal"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IRL",
   "language": "python",
   "name": "irl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
